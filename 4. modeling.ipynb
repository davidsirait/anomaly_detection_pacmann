{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import src.utils as utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_dataset_path': 'data/raw/data.csv',\n",
       " 'data_set_path': 'data/output/data.pkl',\n",
       " 'input_set_path': 'data/output/input.pkl',\n",
       " 'output_set_path': 'data/output/output.pkl',\n",
       " 'input_columns_path': 'data/output/input_columns.pkl',\n",
       " 'train_set_path': ['data/output/X_train.pkl', 'data/output/y_train.pkl'],\n",
       " 'valid_set_path': ['data/output/X_valid.pkl', 'data/output/y_valid.pkl'],\n",
       " 'test_set_path': ['data/output/X_test.pkl', 'data/output/y_test.pkl'],\n",
       " 'output_column': 'Class',\n",
       " 'seed': 42,\n",
       " 'test_size': 0.2,\n",
       " 'standardizer_path': 'data/output/standardizer.pkl',\n",
       " 'preprocessor_path': 'data/output/preprocessor.pkl',\n",
       " 'train_clean_path': ['data/output/X_train_clean.pkl',\n",
       "  'data/output/y_train_clean.pkl'],\n",
       " 'valid_clean_path': ['data/output/X_valid_clean.pkl',\n",
       "  'data/output/y_valid_clean.pkl'],\n",
       " 'test_clean_path': ['data/output/X_test_clean.pkl',\n",
       "  'data/output/y_test_clean.pkl'],\n",
       " 'list_of_model_path': 'log/list_of_model.pkl',\n",
       " 'list_of_param_path': 'log/list_of_param.pkl',\n",
       " 'list_of_tuned_model_path': 'log/list_of_tuned_model.pkl',\n",
       " 'best_model_path': 'models/best_model.pkl',\n",
       " 'best_threshold_path': 'models/best_threshold.pkl'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG_DATA = utils.config_load()\n",
    "CONFIG_DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model of Choice\n",
    "- KNN\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_param():\n",
    "    \"\"\"Create the model objects\"\"\"\n",
    "    knn_params = {\n",
    "        'n_neighbors': [50, 100, 200],\n",
    "    }\n",
    "    \n",
    "    rf_params = {\n",
    "        \"n_estimators\" : [i for i in range(50, 151, 30)],\n",
    "        \"min_samples_split\" : [2, 4, 6, 8],\n",
    "        \"criterion\" : [\"gini\", \"entropy\", \"log_loss\"]\n",
    "    }\n",
    "\n",
    "    lgr_params = {\n",
    "        # 'penalty': ['l1', 'l2'],\n",
    "        'C': [0.01, 0.1],\n",
    "        'max_iter': [100, 300, 500]\n",
    "    }\n",
    "\n",
    "    xgb_params = {\n",
    "        'n_estimators': [5, 10, 25, 50]\n",
    "    }\n",
    "\n",
    "    # Create model params\n",
    "    list_of_param = {\n",
    "        'KNeighborsClassifier': knn_params,\n",
    "        'RandomForestClassifier': rf_params,\n",
    "        'LogisticRegression': lgr_params,\n",
    "        'XGBClassifier': xgb_params\n",
    "    }\n",
    "\n",
    "    return list_of_param\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_object():\n",
    "    \"\"\"Create the model objects\"\"\"\n",
    "    print(\"Creating model objects\")\n",
    "\n",
    "    # Create model objects\n",
    "    knn = KNeighborsClassifier()\n",
    "    rf = RandomForestClassifier()\n",
    "    lgr = LogisticRegression(solver='sag') # \n",
    "    xgb = XGBClassifier()\n",
    "\n",
    "    # Create list of model\n",
    "    list_of_model = [\n",
    "        {'model_name': knn.__class__.__name__, 'model_object': knn},\n",
    "        {'model_name': rf.__class__.__name__, 'model_object': rf},\n",
    "        {'model_name': lgr.__class__.__name__, 'model_object': lgr},\n",
    "        {'model_name': xgb.__class__.__name__, 'model_object': xgb}\n",
    "    ]\n",
    "\n",
    "    return list_of_model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model objects\n"
     ]
    }
   ],
   "source": [
    "list_of_param = create_model_param()\n",
    "list_of_model = create_model_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNeighborsClassifier': {'n_neighbors': [50, 100, 200]},\n",
       " 'RandomForestClassifier': {'n_estimators': [50, 80, 110, 140],\n",
       "  'min_samples_split': [2, 4, 6, 8],\n",
       "  'criterion': ['gini', 'entropy', 'log_loss']},\n",
       " 'LogisticRegression': {'C': [0.01, 0.1], 'max_iter': [100, 300, 500]},\n",
       " 'XGBClassifier': {'n_estimators': [5, 10, 25, 50]}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_name': 'KNeighborsClassifier',\n",
       "  'model_object': KNeighborsClassifier()},\n",
       " {'model_name': 'RandomForestClassifier',\n",
       "  'model_object': RandomForestClassifier()},\n",
       " {'model_name': 'LogisticRegression',\n",
       "  'model_object': LogisticRegression(solver='sag')},\n",
       " {'model_name': 'XGBClassifier',\n",
       "  'model_object': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bynode=None,\n",
       "                colsample_bytree=None, early_stopping_rounds=None,\n",
       "                enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "                gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "                interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "                predictor=None, random_state=None, ...)}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(return_file=True):\n",
    "    \"\"\"Function to get the best model\"\"\"\n",
    "    # Load dataset\n",
    "    X_train = utils.pickle_load(CONFIG_DATA['train_clean_path'][0])\n",
    "    y_train = utils.pickle_load(CONFIG_DATA['train_clean_path'][1])\n",
    "    X_valid = utils.pickle_load(CONFIG_DATA['valid_clean_path'][0])\n",
    "    y_valid = utils.pickle_load(CONFIG_DATA['valid_clean_path'][1])\n",
    "    \n",
    "    # Create list of params & models\n",
    "    list_of_param = create_model_param()\n",
    "    list_of_model = create_model_object()\n",
    "\n",
    "    # List of trained model\n",
    "    list_of_tuned_model = {}\n",
    "\n",
    "    # Train model\n",
    "    for base_model in list_of_model:\n",
    "        # Current condition\n",
    "        model_name = base_model['model_name']\n",
    "        model_obj = copy.deepcopy(base_model['model_object'])\n",
    "        model_param = list_of_param[model_name]\n",
    "\n",
    "        # Debug message\n",
    "        print('Training model :', model_name)\n",
    "\n",
    "        # Create model object\n",
    "        model = RandomizedSearchCV(estimator = model_obj,\n",
    "                                   param_distributions = model_param,\n",
    "                                   n_iter=5,\n",
    "                                   cv = 5,\n",
    "                                   random_state = 123,\n",
    "                                   n_jobs=1,\n",
    "                                   verbose=10,\n",
    "                                   scoring = 'roc_auc')\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred_proba_train = model.predict_proba(X_train)[:, 1]\n",
    "        y_pred_proba_valid = model.predict_proba(X_valid)[:, 1]\n",
    "        \n",
    "        # Get score\n",
    "        train_score = roc_auc_score(y_train, y_pred_proba_train)\n",
    "        valid_score = roc_auc_score(y_valid, y_pred_proba_valid)\n",
    "\n",
    "        # Append\n",
    "        list_of_tuned_model[model_name] = {\n",
    "            'model': model,\n",
    "            'train_auc': train_score,\n",
    "            'valid_auc': valid_score,\n",
    "            'best_params': model.best_params_\n",
    "        }\n",
    "\n",
    "        print(\"Done training\")\n",
    "        print(\"\")\n",
    "\n",
    "    # Dump data\n",
    "    utils.pickle_dump(list_of_param, CONFIG_DATA['list_of_param_path'])\n",
    "    utils.pickle_dump(list_of_model, CONFIG_DATA['list_of_model_path'])\n",
    "    utils.pickle_dump(list_of_tuned_model, CONFIG_DATA['list_of_tuned_model_path'])\n",
    "\n",
    "    if return_file:\n",
    "        return list_of_param, list_of_model, list_of_tuned_model    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model objects\n",
      "Training model : KNeighborsClassifier\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 1/5; 1/3] END ...............n_neighbors=50;, score=0.968 total time=   0.0s\n",
      "[CV 2/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 2/5; 1/3] END ...............n_neighbors=50;, score=0.989 total time=   0.0s\n",
      "[CV 3/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 3/5; 1/3] END ...............n_neighbors=50;, score=0.967 total time=   0.0s\n",
      "[CV 4/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 4/5; 1/3] END ...............n_neighbors=50;, score=0.995 total time=   0.0s\n",
      "[CV 5/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 5/5; 1/3] END ...............n_neighbors=50;, score=0.974 total time=   0.0s\n",
      "[CV 1/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 1/5; 2/3] END ..............n_neighbors=100;, score=0.961 total time=   0.0s\n",
      "[CV 2/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 2/5; 2/3] END ..............n_neighbors=100;, score=0.982 total time=   0.0s\n",
      "[CV 3/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 3/5; 2/3] END ..............n_neighbors=100;, score=0.973 total time=   0.0s\n",
      "[CV 4/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 4/5; 2/3] END ..............n_neighbors=100;, score=0.994 total time=   0.0s\n",
      "[CV 5/5; 2/3] START n_neighbors=100.............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 2/3] END ..............n_neighbors=100;, score=0.974 total time=   0.0s\n",
      "[CV 1/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 1/5; 3/3] END ..............n_neighbors=200;, score=0.967 total time=   0.0s\n",
      "[CV 2/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 2/5; 3/3] END ..............n_neighbors=200;, score=0.991 total time=   0.0s\n",
      "[CV 3/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 3/5; 3/3] END ..............n_neighbors=200;, score=0.971 total time=   0.0s\n",
      "[CV 4/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 4/5; 3/3] END ..............n_neighbors=200;, score=0.997 total time=   0.0s\n",
      "[CV 5/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 5/5; 3/3] END ..............n_neighbors=200;, score=0.967 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training\n",
      "\n",
      "Training model : RandomForestClassifier\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV 1/5; 1/5] START criterion=entropy, min_samples_split=2, n_estimators=110....\n",
      "[CV 1/5; 1/5] END criterion=entropy, min_samples_split=2, n_estimators=110;, score=0.979 total time=   0.1s\n",
      "[CV 2/5; 1/5] START criterion=entropy, min_samples_split=2, n_estimators=110....\n",
      "[CV 2/5; 1/5] END criterion=entropy, min_samples_split=2, n_estimators=110;, score=0.979 total time=   0.2s\n",
      "[CV 3/5; 1/5] START criterion=entropy, min_samples_split=2, n_estimators=110....\n",
      "[CV 3/5; 1/5] END criterion=entropy, min_samples_split=2, n_estimators=110;, score=0.982 total time=   0.1s\n",
      "[CV 4/5; 1/5] START criterion=entropy, min_samples_split=2, n_estimators=110....\n",
      "[CV 4/5; 1/5] END criterion=entropy, min_samples_split=2, n_estimators=110;, score=0.999 total time=   0.1s\n",
      "[CV 5/5; 1/5] START criterion=entropy, min_samples_split=2, n_estimators=110....\n",
      "[CV 5/5; 1/5] END criterion=entropy, min_samples_split=2, n_estimators=110;, score=0.973 total time=   0.1s\n",
      "[CV 1/5; 2/5] START criterion=gini, min_samples_split=8, n_estimators=80........\n",
      "[CV 1/5; 2/5] END criterion=gini, min_samples_split=8, n_estimators=80;, score=0.981 total time=   0.1s\n",
      "[CV 2/5; 2/5] START criterion=gini, min_samples_split=8, n_estimators=80........\n",
      "[CV 2/5; 2/5] END criterion=gini, min_samples_split=8, n_estimators=80;, score=0.983 total time=   0.1s\n",
      "[CV 3/5; 2/5] START criterion=gini, min_samples_split=8, n_estimators=80........\n",
      "[CV 3/5; 2/5] END criterion=gini, min_samples_split=8, n_estimators=80;, score=0.967 total time=   0.1s\n",
      "[CV 4/5; 2/5] START criterion=gini, min_samples_split=8, n_estimators=80........\n",
      "[CV 4/5; 2/5] END criterion=gini, min_samples_split=8, n_estimators=80;, score=0.997 total time=   0.1s\n",
      "[CV 5/5; 2/5] START criterion=gini, min_samples_split=8, n_estimators=80........\n",
      "[CV 5/5; 2/5] END criterion=gini, min_samples_split=8, n_estimators=80;, score=0.974 total time=   0.1s\n",
      "[CV 1/5; 3/5] START criterion=entropy, min_samples_split=6, n_estimators=110....\n",
      "[CV 1/5; 3/5] END criterion=entropy, min_samples_split=6, n_estimators=110;, score=0.979 total time=   0.1s\n",
      "[CV 2/5; 3/5] START criterion=entropy, min_samples_split=6, n_estimators=110....\n",
      "[CV 2/5; 3/5] END criterion=entropy, min_samples_split=6, n_estimators=110;, score=0.983 total time=   0.1s\n",
      "[CV 3/5; 3/5] START criterion=entropy, min_samples_split=6, n_estimators=110....\n",
      "[CV 3/5; 3/5] END criterion=entropy, min_samples_split=6, n_estimators=110;, score=0.979 total time=   0.1s\n",
      "[CV 4/5; 3/5] START criterion=entropy, min_samples_split=6, n_estimators=110....\n",
      "[CV 4/5; 3/5] END criterion=entropy, min_samples_split=6, n_estimators=110;, score=0.998 total time=   0.1s\n",
      "[CV 5/5; 3/5] START criterion=entropy, min_samples_split=6, n_estimators=110....\n",
      "[CV 5/5; 3/5] END criterion=entropy, min_samples_split=6, n_estimators=110;, score=0.974 total time=   0.1s\n",
      "[CV 1/5; 4/5] START criterion=entropy, min_samples_split=8, n_estimators=140....\n",
      "[CV 1/5; 4/5] END criterion=entropy, min_samples_split=8, n_estimators=140;, score=0.977 total time=   0.2s\n",
      "[CV 2/5; 4/5] START criterion=entropy, min_samples_split=8, n_estimators=140....\n",
      "[CV 2/5; 4/5] END criterion=entropy, min_samples_split=8, n_estimators=140;, score=0.984 total time=   0.2s\n",
      "[CV 3/5; 4/5] START criterion=entropy, min_samples_split=8, n_estimators=140....\n",
      "[CV 3/5; 4/5] END criterion=entropy, min_samples_split=8, n_estimators=140;, score=0.980 total time=   0.2s\n",
      "[CV 4/5; 4/5] START criterion=entropy, min_samples_split=8, n_estimators=140....\n",
      "[CV 4/5; 4/5] END criterion=entropy, min_samples_split=8, n_estimators=140;, score=0.998 total time=   0.2s\n",
      "[CV 5/5; 4/5] START criterion=entropy, min_samples_split=8, n_estimators=140....\n",
      "[CV 5/5; 4/5] END criterion=entropy, min_samples_split=8, n_estimators=140;, score=0.980 total time=   0.2s\n",
      "[CV 1/5; 5/5] START criterion=gini, min_samples_split=6, n_estimators=110.......\n",
      "[CV 1/5; 5/5] END criterion=gini, min_samples_split=6, n_estimators=110;, score=0.976 total time=   0.1s\n",
      "[CV 2/5; 5/5] START criterion=gini, min_samples_split=6, n_estimators=110.......\n",
      "[CV 2/5; 5/5] END criterion=gini, min_samples_split=6, n_estimators=110;, score=0.980 total time=   0.1s\n",
      "[CV 3/5; 5/5] START criterion=gini, min_samples_split=6, n_estimators=110.......\n",
      "[CV 3/5; 5/5] END criterion=gini, min_samples_split=6, n_estimators=110;, score=0.975 total time=   0.1s\n",
      "[CV 4/5; 5/5] START criterion=gini, min_samples_split=6, n_estimators=110.......\n",
      "[CV 4/5; 5/5] END criterion=gini, min_samples_split=6, n_estimators=110;, score=0.997 total time=   0.1s\n",
      "[CV 5/5; 5/5] START criterion=gini, min_samples_split=6, n_estimators=110.......\n",
      "[CV 5/5; 5/5] END criterion=gini, min_samples_split=6, n_estimators=110;, score=0.968 total time=   0.1s\n",
      "Done training\n",
      "\n",
      "Training model : LogisticRegression\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV 1/5; 1/5] START C=0.01, max_iter=300........................................\n",
      "[CV 1/5; 1/5] END .........C=0.01, max_iter=300;, score=0.968 total time=   0.0s\n",
      "[CV 2/5; 1/5] START C=0.01, max_iter=300........................................\n",
      "[CV 2/5; 1/5] END .........C=0.01, max_iter=300;, score=0.986 total time=   0.0s\n",
      "[CV 3/5; 1/5] START C=0.01, max_iter=300........................................\n",
      "[CV 3/5; 1/5] END .........C=0.01, max_iter=300;, score=0.984 total time=   0.0s\n",
      "[CV 4/5; 1/5] START C=0.01, max_iter=300........................................\n",
      "[CV 4/5; 1/5] END .........C=0.01, max_iter=300;, score=0.998 total time=   0.0s\n",
      "[CV 5/5; 1/5] START C=0.01, max_iter=300........................................\n",
      "[CV 5/5; 1/5] END .........C=0.01, max_iter=300;, score=0.979 total time=   0.0s\n",
      "[CV 1/5; 2/5] START C=0.1, max_iter=100.........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/5] END ..........C=0.1, max_iter=100;, score=0.965 total time=   0.0s\n",
      "[CV 2/5; 2/5] START C=0.1, max_iter=100.........................................\n",
      "[CV 2/5; 2/5] END ..........C=0.1, max_iter=100;, score=0.990 total time=   0.0s\n",
      "[CV 3/5; 2/5] START C=0.1, max_iter=100.........................................\n",
      "[CV 3/5; 2/5] END ..........C=0.1, max_iter=100;, score=0.982 total time=   0.0s\n",
      "[CV 4/5; 2/5] START C=0.1, max_iter=100.........................................\n",
      "[CV 4/5; 2/5] END ..........C=0.1, max_iter=100;, score=0.995 total time=   0.0s\n",
      "[CV 5/5; 2/5] START C=0.1, max_iter=100.........................................\n",
      "[CV 5/5; 2/5] END ..........C=0.1, max_iter=100;, score=0.972 total time=   0.0s\n",
      "[CV 1/5; 3/5] START C=0.1, max_iter=300.........................................\n",
      "[CV 1/5; 3/5] END ..........C=0.1, max_iter=300;, score=0.971 total time=   0.0s\n",
      "[CV 2/5; 3/5] START C=0.1, max_iter=300.........................................\n",
      "[CV 2/5; 3/5] END ..........C=0.1, max_iter=300;, score=0.988 total time=   0.0s\n",
      "[CV 3/5; 3/5] START C=0.1, max_iter=300.........................................\n",
      "[CV 3/5; 3/5] END ..........C=0.1, max_iter=300;, score=0.983 total time=   0.0s\n",
      "[CV 4/5; 3/5] START C=0.1, max_iter=300.........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/5] END ..........C=0.1, max_iter=300;, score=0.997 total time=   0.0s\n",
      "[CV 5/5; 3/5] START C=0.1, max_iter=300.........................................\n",
      "[CV 5/5; 3/5] END ..........C=0.1, max_iter=300;, score=0.972 total time=   0.0s\n",
      "[CV 1/5; 4/5] START C=0.01, max_iter=100........................................\n",
      "[CV 1/5; 4/5] END .........C=0.01, max_iter=100;, score=0.968 total time=   0.0s\n",
      "[CV 2/5; 4/5] START C=0.01, max_iter=100........................................\n",
      "[CV 2/5; 4/5] END .........C=0.01, max_iter=100;, score=0.988 total time=   0.0s\n",
      "[CV 3/5; 4/5] START C=0.01, max_iter=100........................................\n",
      "[CV 3/5; 4/5] END .........C=0.01, max_iter=100;, score=0.984 total time=   0.0s\n",
      "[CV 4/5; 4/5] START C=0.01, max_iter=100........................................\n",
      "[CV 4/5; 4/5] END .........C=0.01, max_iter=100;, score=0.998 total time=   0.0s\n",
      "[CV 5/5; 4/5] START C=0.01, max_iter=100........................................\n",
      "[CV 5/5; 4/5] END .........C=0.01, max_iter=100;, score=0.979 total time=   0.0s\n",
      "[CV 1/5; 5/5] START C=0.01, max_iter=500........................................\n",
      "[CV 1/5; 5/5] END .........C=0.01, max_iter=500;, score=0.968 total time=   0.0s\n",
      "[CV 2/5; 5/5] START C=0.01, max_iter=500........................................\n",
      "[CV 2/5; 5/5] END .........C=0.01, max_iter=500;, score=0.986 total time=   0.0s\n",
      "[CV 3/5; 5/5] START C=0.01, max_iter=500........................................\n",
      "[CV 3/5; 5/5] END .........C=0.01, max_iter=500;, score=0.984 total time=   0.0s\n",
      "[CV 4/5; 5/5] START C=0.01, max_iter=500........................................\n",
      "[CV 4/5; 5/5] END .........C=0.01, max_iter=500;, score=0.998 total time=   0.0s\n",
      "[CV 5/5; 5/5] START C=0.01, max_iter=500........................................\n",
      "[CV 5/5; 5/5] END .........C=0.01, max_iter=500;, score=0.979 total time=   0.0s\n",
      "Done training\n",
      "\n",
      "Training model : XGBClassifier\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5; 1/4] START n_estimators=5..............................................\n",
      "[CV 1/5; 1/4] END ...............n_estimators=5;, score=0.972 total time=   0.0s\n",
      "[CV 2/5; 1/4] START n_estimators=5..............................................\n",
      "[CV 2/5; 1/4] END ...............n_estimators=5;, score=0.987 total time=   0.0s\n",
      "[CV 3/5; 1/4] START n_estimators=5..............................................\n",
      "[CV 3/5; 1/4] END ...............n_estimators=5;, score=0.967 total time=   0.0s\n",
      "[CV 4/5; 1/4] START n_estimators=5..............................................\n",
      "[CV 4/5; 1/4] END ...............n_estimators=5;, score=0.993 total time=   0.0s\n",
      "[CV 5/5; 1/4] START n_estimators=5..............................................\n",
      "[CV 5/5; 1/4] END ...............n_estimators=5;, score=0.971 total time=   0.0s\n",
      "[CV 1/5; 2/4] START n_estimators=10.............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/4] END ..............n_estimators=10;, score=0.967 total time=   0.0s\n",
      "[CV 2/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 2/5; 2/4] END ..............n_estimators=10;, score=0.981 total time=   0.0s\n",
      "[CV 3/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 3/5; 2/4] END ..............n_estimators=10;, score=0.973 total time=   0.0s\n",
      "[CV 4/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 4/5; 2/4] END ..............n_estimators=10;, score=0.994 total time=   0.0s\n",
      "[CV 5/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 5/5; 2/4] END ..............n_estimators=10;, score=0.976 total time=   0.0s\n",
      "[CV 1/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 1/5; 3/4] END ..............n_estimators=25;, score=0.974 total time=   0.0s\n",
      "[CV 2/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 2/5; 3/4] END ..............n_estimators=25;, score=0.978 total time=   0.0s\n",
      "[CV 3/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 3/5; 3/4] END ..............n_estimators=25;, score=0.978 total time=   0.0s\n",
      "[CV 4/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 4/5; 3/4] END ..............n_estimators=25;, score=0.994 total time=   0.0s\n",
      "[CV 5/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 5/5; 3/4] END ..............n_estimators=25;, score=0.978 total time=   0.0s\n",
      "[CV 1/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 1/5; 4/4] END ..............n_estimators=50;, score=0.969 total time=   0.0s\n",
      "[CV 2/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 2/5; 4/4] END ..............n_estimators=50;, score=0.979 total time=   0.0s\n",
      "[CV 3/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 3/5; 4/4] END ..............n_estimators=50;, score=0.976 total time=   0.0s\n",
      "[CV 4/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 4/5; 4/4] END ..............n_estimators=50;, score=0.995 total time=   0.0s\n",
      "[CV 5/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 5/5; 4/4] END ..............n_estimators=50;, score=0.980 total time=   0.0s\n",
      "Done training\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_of_param, list_of_model, list_of_tuned_model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNeighborsClassifier': {'model': RandomizedSearchCV(cv=5, estimator=KNeighborsClassifier(), n_iter=5, n_jobs=1,\n",
       "                     param_distributions={'n_neighbors': [50, 100, 200]},\n",
       "                     random_state=123, scoring='roc_auc', verbose=10),\n",
       "  'train_auc': 0.9822038567493112,\n",
       "  'valid_auc': 0.9722329620371388,\n",
       "  'best_params': {'n_neighbors': 200}},\n",
       " 'RandomForestClassifier': {'model': RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=5, n_jobs=1,\n",
       "                     param_distributions={'criterion': ['gini', 'entropy',\n",
       "                                                        'log_loss'],\n",
       "                                          'min_samples_split': [2, 4, 6, 8],\n",
       "                                          'n_estimators': [50, 80, 110, 140]},\n",
       "                     random_state=123, scoring='roc_auc', verbose=10),\n",
       "  'train_auc': 0.999880624426079,\n",
       "  'valid_auc': 0.981115056037798,\n",
       "  'best_params': {'n_estimators': 140,\n",
       "   'min_samples_split': 8,\n",
       "   'criterion': 'entropy'}},\n",
       " 'LogisticRegression': {'model': RandomizedSearchCV(cv=5, estimator=LogisticRegression(solver='sag'), n_iter=5,\n",
       "                     n_jobs=1,\n",
       "                     param_distributions={'C': [0.01, 0.1],\n",
       "                                          'max_iter': [100, 300, 500]},\n",
       "                     random_state=123, scoring='roc_auc', verbose=10),\n",
       "  'train_auc': 0.9864462809917355,\n",
       "  'valid_auc': 0.9765705691682233,\n",
       "  'best_params': {'max_iter': 100, 'C': 0.01}},\n",
       " 'XGBClassifier': {'model': RandomizedSearchCV(cv=5,\n",
       "                     estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                             callbacks=None,\n",
       "                                             colsample_bylevel=None,\n",
       "                                             colsample_bynode=None,\n",
       "                                             colsample_bytree=None,\n",
       "                                             early_stopping_rounds=None,\n",
       "                                             enable_categorical=False,\n",
       "                                             eval_metric=None, feature_types=None,\n",
       "                                             gamma=None, gpu_id=None,\n",
       "                                             grow_policy=None,\n",
       "                                             importance_type=None,\n",
       "                                             interaction_constraints=None,\n",
       "                                             learning_rate...\n",
       "                                             max_cat_threshold=None,\n",
       "                                             max_cat_to_onehot=None,\n",
       "                                             max_delta_step=None, max_depth=None,\n",
       "                                             max_leaves=None,\n",
       "                                             min_child_weight=None, missing=nan,\n",
       "                                             monotone_constraints=None,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             num_parallel_tree=None,\n",
       "                                             predictor=None, random_state=None, ...),\n",
       "                     n_iter=5, n_jobs=1,\n",
       "                     param_distributions={'n_estimators': [5, 10, 25, 50]},\n",
       "                     random_state=123, scoring='roc_auc', verbose=10),\n",
       "  'train_auc': 1.0,\n",
       "  'valid_auc': 0.9788072739259421,\n",
       "  'best_params': {'n_estimators': 25}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_tuned_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(return_file=True):\n",
    "    \"\"\"Function to get the best model\"\"\"\n",
    "    # Load tuned model\n",
    "    list_of_tuned_model = utils.pickle_load(CONFIG_DATA['list_of_tuned_model_path'])\n",
    "\n",
    "    # Get the best model\n",
    "    best_model_name = None\n",
    "    best_model = None\n",
    "    best_performance = -99999\n",
    "    best_model_param = None\n",
    "\n",
    "    for model_name, model in list_of_tuned_model.items():\n",
    "        if model['valid_auc'] > best_performance:\n",
    "            best_model_name = model_name\n",
    "            best_model = model['model']\n",
    "            best_performance = model['valid_auc']\n",
    "            best_model_param = model['best_params']\n",
    "\n",
    "    # Dump the best model\n",
    "    utils.pickle_dump(best_model, CONFIG_DATA['best_model_path'])\n",
    "\n",
    "    # Print\n",
    "    print('=============================================')\n",
    "    print('Best model        :', best_model_name)\n",
    "    print('Metric score      :', best_performance)\n",
    "    print('Best model params :', best_model_param)\n",
    "    print('=============================================')\n",
    "\n",
    "    if return_file:\n",
    "        return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "Best model        : RandomForestClassifier\n",
      "Metric score      : 0.981115056037798\n",
      "Best model params : {'n_estimators': 140, 'min_samples_split': 8, 'criterion': 'entropy'}\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "best_model = get_best_model()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = utils.pickle_load(CONFIG_DATA['test_clean_path'][0])\n",
    "y_test = utils.pickle_load(CONFIG_DATA['test_clean_path'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Get score\n",
    "score = roc_auc_score(y_test, y_test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9785603746281856"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
