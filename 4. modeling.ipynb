{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import src.utils as utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_dataset_path': 'data/raw/data.csv',\n",
       " 'data_set_path': 'data/output/data.pkl',\n",
       " 'input_set_path': 'data/output/input.pkl',\n",
       " 'output_set_path': 'data/output/output.pkl',\n",
       " 'input_columns_path': 'data/output/input_columns.pkl',\n",
       " 'train_set_path': ['data/output/X_train.pkl', 'data/output/y_train.pkl'],\n",
       " 'valid_set_path': ['data/output/X_valid.pkl', 'data/output/y_valid.pkl'],\n",
       " 'test_set_path': ['data/output/X_test.pkl', 'data/output/y_test.pkl'],\n",
       " 'output_column': 'Class',\n",
       " 'seed': 42,\n",
       " 'test_size': 0.2,\n",
       " 'standardizer_path': 'data/output/standardizer.pkl',\n",
       " 'preprocessor_path': 'data/output/preprocessor.pkl',\n",
       " 'train_clean_path': ['data/output/X_train_clean.pkl',\n",
       "  'data/output/y_train_clean.pkl'],\n",
       " 'valid_clean_path': ['data/output/X_valid_clean.pkl',\n",
       "  'data/output/y_valid_clean.pkl'],\n",
       " 'test_clean_path': ['data/output/X_test_clean.pkl',\n",
       "  'data/output/y_test_clean.pkl'],\n",
       " 'list_of_model_path': 'log/list_of_model.pkl',\n",
       " 'list_of_param_path': 'log/list_of_param.pkl',\n",
       " 'list_of_tuned_model_path': 'log/list_of_tuned_model.pkl',\n",
       " 'best_model_path': 'models/best_model.pkl',\n",
       " 'best_threshold_path': 'models/best_threshold.pkl'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG_DATA = utils.config_load()\n",
    "CONFIG_DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model of Choice\n",
    "- KNN\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_param():\n",
    "    \"\"\"Create the model objects\"\"\"\n",
    "    knn_params = {\n",
    "        'n_neighbors': [50, 100, 200],\n",
    "    }\n",
    "    \n",
    "    rf_params = {\n",
    "        \"n_estimators\" : [i for i in range(50, 150, 30)],\n",
    "        \"min_samples_split\" : [2, 4, 6, 8],\n",
    "        \"criterion\" : [\"gini\", \"entropy\", \"log_loss\"]\n",
    "    }\n",
    "\n",
    "    lgr_params = {\n",
    "        # 'penalty': ['l1', 'l2'],\n",
    "        'C': [0.01, 0.1],\n",
    "        'max_iter': [100, 300, 500]\n",
    "    }\n",
    "\n",
    "    xgb_params = {\n",
    "        'n_estimators': [5, 10, 25, 50]\n",
    "    }\n",
    "\n",
    "    # Create model params\n",
    "    list_of_param = {\n",
    "        'KNeighborsClassifier': knn_params,\n",
    "        'RandomForestClassifier': rf_params,\n",
    "        'LogisticRegression': lgr_params,\n",
    "        'XGBClassifier': xgb_params\n",
    "    }\n",
    "\n",
    "    return list_of_param\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_object():\n",
    "    \"\"\"Create the model objects\"\"\"\n",
    "    print(\"Creating model objects\")\n",
    "\n",
    "    # Create model objects\n",
    "    knn = KNeighborsClassifier()\n",
    "    rf = RandomForestClassifier()\n",
    "    lgr = LogisticRegression(solver='sag') # \n",
    "    xgb = XGBClassifier()\n",
    "\n",
    "    # Create list of model\n",
    "    list_of_model = [\n",
    "        {'model_name': knn.__class__.__name__, 'model_object': knn},\n",
    "        {'model_name': rf.__class__.__name__, 'model_object': rf},\n",
    "        {'model_name': lgr.__class__.__name__, 'model_object': lgr},\n",
    "        {'model_name': xgb.__class__.__name__, 'model_object': xgb}\n",
    "    ]\n",
    "\n",
    "    return list_of_model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(return_file=True):\n",
    "    \"\"\"Function to get the best model\"\"\"\n",
    "    # Load dataset\n",
    "    X_train = utils.pickle_load(CONFIG_DATA['train_clean_path'][0])\n",
    "    y_train = utils.pickle_load(CONFIG_DATA['train_clean_path'][1])\n",
    "    X_valid = utils.pickle_load(CONFIG_DATA['valid_clean_path'][0])\n",
    "    y_valid = utils.pickle_load(CONFIG_DATA['valid_clean_path'][1])\n",
    "    \n",
    "    # Create list of params & models\n",
    "    list_of_param = create_model_param()\n",
    "    list_of_model = create_model_object()\n",
    "\n",
    "    # List of trained model\n",
    "    list_of_tuned_model = {}\n",
    "\n",
    "    # Train model\n",
    "    for base_model in list_of_model:\n",
    "        # Current condition\n",
    "        model_name = base_model['model_name']\n",
    "        model_obj = copy.deepcopy(base_model['model_object'])\n",
    "        model_param = list_of_param[model_name]\n",
    "\n",
    "        # Debug message\n",
    "        print('Training model :', model_name)\n",
    "\n",
    "        # Create model object\n",
    "        model = RandomizedSearchCV(estimator = model_obj,\n",
    "                                   param_distributions = model_param,\n",
    "                                   n_iter=5,\n",
    "                                   cv = 5,\n",
    "                                   random_state = 123,\n",
    "                                   n_jobs=1,\n",
    "                                   verbose=10,\n",
    "                                   scoring = 'roc_auc')\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred_proba_train = model.predict_proba(X_train)[:, 1]\n",
    "        y_pred_proba_valid = model.predict_proba(X_valid)[:, 1]\n",
    "        \n",
    "        # Get score\n",
    "        train_score = roc_auc_score(y_train, y_pred_proba_train)\n",
    "        valid_score = roc_auc_score(y_valid, y_pred_proba_valid)\n",
    "\n",
    "        # Append\n",
    "        list_of_tuned_model[model_name] = {\n",
    "            'model': model,\n",
    "            'train_auc': train_score,\n",
    "            'valid_auc': valid_score,\n",
    "            'best_params': model.best_params_\n",
    "        }\n",
    "\n",
    "        print(\"Done training\")\n",
    "        print(\"\")\n",
    "\n",
    "    # Dump data\n",
    "    utils.pickle_dump(list_of_param, CONFIG_DATA['list_of_param_path'])\n",
    "    utils.pickle_dump(list_of_model, CONFIG_DATA['list_of_model_path'])\n",
    "    utils.pickle_dump(list_of_tuned_model, CONFIG_DATA['list_of_tuned_model_path'])\n",
    "\n",
    "    if return_file:\n",
    "        return list_of_param, list_of_model, list_of_tuned_model    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model objects\n",
      "Training model : KNeighborsClassifier\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 1/5; 1/3] END ...............n_neighbors=50;, score=0.968 total time=   0.0s\n",
      "[CV 2/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 2/5; 1/3] END ...............n_neighbors=50;, score=0.989 total time=   0.0s\n",
      "[CV 3/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 3/5; 1/3] END ...............n_neighbors=50;, score=0.967 total time=   0.0s\n",
      "[CV 4/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 4/5; 1/3] END ...............n_neighbors=50;, score=0.995 total time=   0.0s\n",
      "[CV 5/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 5/5; 1/3] END ...............n_neighbors=50;, score=0.974 total time=   0.0s\n",
      "[CV 1/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 1/5; 2/3] END ..............n_neighbors=100;, score=0.961 total time=   0.0s\n",
      "[CV 2/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 2/5; 2/3] END ..............n_neighbors=100;, score=0.982 total time=   0.0s\n",
      "[CV 3/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 3/5; 2/3] END ..............n_neighbors=100;, score=0.973 total time=   0.0s\n",
      "[CV 4/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 4/5; 2/3] END ..............n_neighbors=100;, score=0.994 total time=   0.0s\n",
      "[CV 5/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 5/5; 2/3] END ..............n_neighbors=100;, score=0.974 total time=   0.0s\n",
      "[CV 1/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 1/5; 3/3] END ..............n_neighbors=200;, score=0.967 total time=   0.0s\n",
      "[CV 2/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 2/5; 3/3] END ..............n_neighbors=200;, score=0.991 total time=   0.0s\n",
      "[CV 3/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 3/5; 3/3] END ..............n_neighbors=200;, score=0.971 total time=   0.0s\n",
      "[CV 4/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 4/5; 3/3] END ..............n_neighbors=200;, score=0.997 total time=   0.0s\n",
      "[CV 5/5; 3/3] START n_neighbors=200.............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/3] END ..............n_neighbors=200;, score=0.967 total time=   0.0s\n",
      "Done training\n",
      "\n",
      "Training model : RandomForestClassifier\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV 1/5; 1/5] START criterion=entropy, min_samples_split=2, n_estimators=110....\n",
      "[CV 1/5; 1/5] END criterion=entropy, min_samples_split=2, n_estimators=110;, score=0.979 total time=   0.2s\n",
      "[CV 2/5; 1/5] START criterion=entropy, min_samples_split=2, n_estimators=110....\n",
      "[CV 2/5; 1/5] END criterion=entropy, min_samples_split=2, n_estimators=110;, score=0.982 total time=   0.2s\n",
      "[CV 3/5; 1/5] START criterion=entropy, min_samples_split=2, n_estimators=110....\n",
      "[CV 3/5; 1/5] END criterion=entropy, min_samples_split=2, n_estimators=110;, score=0.975 total time=   0.1s\n",
      "[CV 4/5; 1/5] START criterion=entropy, min_samples_split=2, n_estimators=110....\n",
      "[CV 4/5; 1/5] END criterion=entropy, min_samples_split=2, n_estimators=110;, score=0.998 total time=   0.2s\n",
      "[CV 5/5; 1/5] START criterion=entropy, min_samples_split=2, n_estimators=110....\n",
      "[CV 5/5; 1/5] END criterion=entropy, min_samples_split=2, n_estimators=110;, score=0.973 total time=   0.1s\n",
      "[CV 1/5; 2/5] START criterion=gini, min_samples_split=8, n_estimators=80........\n",
      "[CV 1/5; 2/5] END criterion=gini, min_samples_split=8, n_estimators=80;, score=0.979 total time=   0.1s\n",
      "[CV 2/5; 2/5] START criterion=gini, min_samples_split=8, n_estimators=80........\n",
      "[CV 2/5; 2/5] END criterion=gini, min_samples_split=8, n_estimators=80;, score=0.981 total time=   0.1s\n",
      "[CV 3/5; 2/5] START criterion=gini, min_samples_split=8, n_estimators=80........\n",
      "[CV 3/5; 2/5] END criterion=gini, min_samples_split=8, n_estimators=80;, score=0.976 total time=   0.1s\n",
      "[CV 4/5; 2/5] START criterion=gini, min_samples_split=8, n_estimators=80........\n",
      "[CV 4/5; 2/5] END criterion=gini, min_samples_split=8, n_estimators=80;, score=0.997 total time=   0.1s\n",
      "[CV 5/5; 2/5] START criterion=gini, min_samples_split=8, n_estimators=80........\n",
      "[CV 5/5; 2/5] END criterion=gini, min_samples_split=8, n_estimators=80;, score=0.966 total time=   0.1s\n",
      "[CV 1/5; 3/5] START criterion=entropy, min_samples_split=6, n_estimators=110....\n",
      "[CV 1/5; 3/5] END criterion=entropy, min_samples_split=6, n_estimators=110;, score=0.977 total time=   0.2s\n",
      "[CV 2/5; 3/5] START criterion=entropy, min_samples_split=6, n_estimators=110....\n",
      "[CV 2/5; 3/5] END criterion=entropy, min_samples_split=6, n_estimators=110;, score=0.980 total time=   0.1s\n",
      "[CV 3/5; 3/5] START criterion=entropy, min_samples_split=6, n_estimators=110....\n",
      "[CV 3/5; 3/5] END criterion=entropy, min_samples_split=6, n_estimators=110;, score=0.977 total time=   0.1s\n",
      "[CV 4/5; 3/5] START criterion=entropy, min_samples_split=6, n_estimators=110....\n",
      "[CV 4/5; 3/5] END criterion=entropy, min_samples_split=6, n_estimators=110;, score=0.999 total time=   0.2s\n",
      "[CV 5/5; 3/5] START criterion=entropy, min_samples_split=6, n_estimators=110....\n",
      "[CV 5/5; 3/5] END criterion=entropy, min_samples_split=6, n_estimators=110;, score=0.977 total time=   0.2s\n",
      "[CV 1/5; 4/5] START criterion=entropy, min_samples_split=8, n_estimators=140....\n",
      "[CV 1/5; 4/5] END criterion=entropy, min_samples_split=8, n_estimators=140;, score=0.980 total time=   0.2s\n",
      "[CV 2/5; 4/5] START criterion=entropy, min_samples_split=8, n_estimators=140....\n",
      "[CV 2/5; 4/5] END criterion=entropy, min_samples_split=8, n_estimators=140;, score=0.982 total time=   0.3s\n",
      "[CV 3/5; 4/5] START criterion=entropy, min_samples_split=8, n_estimators=140....\n",
      "[CV 3/5; 4/5] END criterion=entropy, min_samples_split=8, n_estimators=140;, score=0.979 total time=   0.2s\n",
      "[CV 4/5; 4/5] START criterion=entropy, min_samples_split=8, n_estimators=140....\n",
      "[CV 4/5; 4/5] END criterion=entropy, min_samples_split=8, n_estimators=140;, score=0.998 total time=   0.2s\n",
      "[CV 5/5; 4/5] START criterion=entropy, min_samples_split=8, n_estimators=140....\n",
      "[CV 5/5; 4/5] END criterion=entropy, min_samples_split=8, n_estimators=140;, score=0.976 total time=   0.2s\n",
      "[CV 1/5; 5/5] START criterion=gini, min_samples_split=6, n_estimators=110.......\n",
      "[CV 1/5; 5/5] END criterion=gini, min_samples_split=6, n_estimators=110;, score=0.978 total time=   0.1s\n",
      "[CV 2/5; 5/5] START criterion=gini, min_samples_split=6, n_estimators=110.......\n",
      "[CV 2/5; 5/5] END criterion=gini, min_samples_split=6, n_estimators=110;, score=0.983 total time=   0.1s\n",
      "[CV 3/5; 5/5] START criterion=gini, min_samples_split=6, n_estimators=110.......\n",
      "[CV 3/5; 5/5] END criterion=gini, min_samples_split=6, n_estimators=110;, score=0.975 total time=   0.1s\n",
      "[CV 4/5; 5/5] START criterion=gini, min_samples_split=6, n_estimators=110.......\n",
      "[CV 4/5; 5/5] END criterion=gini, min_samples_split=6, n_estimators=110;, score=0.996 total time=   0.1s\n",
      "[CV 5/5; 5/5] START criterion=gini, min_samples_split=6, n_estimators=110.......\n",
      "[CV 5/5; 5/5] END criterion=gini, min_samples_split=6, n_estimators=110;, score=0.971 total time=   0.1s\n",
      "Done training\n",
      "\n",
      "Training model : LogisticRegression\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV 1/5; 1/5] START C=0.01, max_iter=300........................................\n",
      "[CV 1/5; 1/5] END .........C=0.01, max_iter=300;, score=0.968 total time=   0.0s\n",
      "[CV 2/5; 1/5] START C=0.01, max_iter=300........................................\n",
      "[CV 2/5; 1/5] END .........C=0.01, max_iter=300;, score=0.986 total time=   0.0s\n",
      "[CV 3/5; 1/5] START C=0.01, max_iter=300........................................\n",
      "[CV 3/5; 1/5] END .........C=0.01, max_iter=300;, score=0.984 total time=   0.0s\n",
      "[CV 4/5; 1/5] START C=0.01, max_iter=300........................................\n",
      "[CV 4/5; 1/5] END .........C=0.01, max_iter=300;, score=0.998 total time=   0.0s\n",
      "[CV 5/5; 1/5] START C=0.01, max_iter=300........................................\n",
      "[CV 5/5; 1/5] END .........C=0.01, max_iter=300;, score=0.979 total time=   0.0s\n",
      "[CV 1/5; 2/5] START C=0.1, max_iter=100.........................................\n",
      "[CV 1/5; 2/5] END ..........C=0.1, max_iter=100;, score=0.965 total time=   0.0s\n",
      "[CV 2/5; 2/5] START C=0.1, max_iter=100.........................................\n",
      "[CV 2/5; 2/5] END ..........C=0.1, max_iter=100;, score=0.990 total time=   0.0s\n",
      "[CV 3/5; 2/5] START C=0.1, max_iter=100.........................................\n",
      "[CV 3/5; 2/5] END ..........C=0.1, max_iter=100;, score=0.982 total time=   0.0s\n",
      "[CV 4/5; 2/5] START C=0.1, max_iter=100.........................................\n",
      "[CV 4/5; 2/5] END ..........C=0.1, max_iter=100;, score=0.995 total time=   0.0s\n",
      "[CV 5/5; 2/5] START C=0.1, max_iter=100.........................................\n",
      "[CV 5/5; 2/5] END ..........C=0.1, max_iter=100;, score=0.972 total time=   0.0s\n",
      "[CV 1/5; 3/5] START C=0.1, max_iter=300.........................................\n",
      "[CV 1/5; 3/5] END ..........C=0.1, max_iter=300;, score=0.971 total time=   0.0s\n",
      "[CV 2/5; 3/5] START C=0.1, max_iter=300.........................................\n",
      "[CV 2/5; 3/5] END ..........C=0.1, max_iter=300;, score=0.988 total time=   0.0s\n",
      "[CV 3/5; 3/5] START C=0.1, max_iter=300.........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 3/5] END ..........C=0.1, max_iter=300;, score=0.983 total time=   0.0s\n",
      "[CV 4/5; 3/5] START C=0.1, max_iter=300.........................................\n",
      "[CV 4/5; 3/5] END ..........C=0.1, max_iter=300;, score=0.997 total time=   0.0s\n",
      "[CV 5/5; 3/5] START C=0.1, max_iter=300.........................................\n",
      "[CV 5/5; 3/5] END ..........C=0.1, max_iter=300;, score=0.972 total time=   0.0s\n",
      "[CV 1/5; 4/5] START C=0.01, max_iter=100........................................\n",
      "[CV 1/5; 4/5] END .........C=0.01, max_iter=100;, score=0.968 total time=   0.0s\n",
      "[CV 2/5; 4/5] START C=0.01, max_iter=100........................................\n",
      "[CV 2/5; 4/5] END .........C=0.01, max_iter=100;, score=0.988 total time=   0.0s\n",
      "[CV 3/5; 4/5] START C=0.01, max_iter=100........................................\n",
      "[CV 3/5; 4/5] END .........C=0.01, max_iter=100;, score=0.984 total time=   0.0s\n",
      "[CV 4/5; 4/5] START C=0.01, max_iter=100........................................\n",
      "[CV 4/5; 4/5] END .........C=0.01, max_iter=100;, score=0.998 total time=   0.0s\n",
      "[CV 5/5; 4/5] START C=0.01, max_iter=100........................................\n",
      "[CV 5/5; 4/5] END .........C=0.01, max_iter=100;, score=0.979 total time=   0.0s\n",
      "[CV 1/5; 5/5] START C=0.01, max_iter=500........................................\n",
      "[CV 1/5; 5/5] END .........C=0.01, max_iter=500;, score=0.968 total time=   0.0s\n",
      "[CV 2/5; 5/5] START C=0.01, max_iter=500........................................\n",
      "[CV 2/5; 5/5] END .........C=0.01, max_iter=500;, score=0.986 total time=   0.0s\n",
      "[CV 3/5; 5/5] START C=0.01, max_iter=500........................................\n",
      "[CV 3/5; 5/5] END .........C=0.01, max_iter=500;, score=0.984 total time=   0.0s\n",
      "[CV 4/5; 5/5] START C=0.01, max_iter=500........................................\n",
      "[CV 4/5; 5/5] END .........C=0.01, max_iter=500;, score=0.998 total time=   0.0s\n",
      "[CV 5/5; 5/5] START C=0.01, max_iter=500........................................\n",
      "[CV 5/5; 5/5] END .........C=0.01, max_iter=500;, score=0.979 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training\n",
      "\n",
      "Training model : XGBClassifier\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5; 1/4] START n_estimators=5..............................................\n",
      "[CV 1/5; 1/4] END ...............n_estimators=5;, score=0.972 total time=   0.0s\n",
      "[CV 2/5; 1/4] START n_estimators=5..............................................\n",
      "[CV 2/5; 1/4] END ...............n_estimators=5;, score=0.987 total time=   0.0s\n",
      "[CV 3/5; 1/4] START n_estimators=5..............................................\n",
      "[CV 3/5; 1/4] END ...............n_estimators=5;, score=0.967 total time=   0.0s\n",
      "[CV 4/5; 1/4] START n_estimators=5..............................................\n",
      "[CV 4/5; 1/4] END ...............n_estimators=5;, score=0.993 total time=   0.0s\n",
      "[CV 5/5; 1/4] START n_estimators=5..............................................\n",
      "[CV 5/5; 1/4] END ...............n_estimators=5;, score=0.971 total time=   0.0s\n",
      "[CV 1/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 1/5; 2/4] END ..............n_estimators=10;, score=0.967 total time=   0.0s\n",
      "[CV 2/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 2/5; 2/4] END ..............n_estimators=10;, score=0.981 total time=   0.0s\n",
      "[CV 3/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 3/5; 2/4] END ..............n_estimators=10;, score=0.973 total time=   0.0s\n",
      "[CV 4/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 4/5; 2/4] END ..............n_estimators=10;, score=0.994 total time=   0.0s\n",
      "[CV 5/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 5/5; 2/4] END ..............n_estimators=10;, score=0.976 total time=   0.0s\n",
      "[CV 1/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 1/5; 3/4] END ..............n_estimators=25;, score=0.974 total time=   0.0s\n",
      "[CV 2/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 2/5; 3/4] END ..............n_estimators=25;, score=0.978 total time=   0.0s\n",
      "[CV 3/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 3/5; 3/4] END ..............n_estimators=25;, score=0.978 total time=   0.0s\n",
      "[CV 4/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 4/5; 3/4] END ..............n_estimators=25;, score=0.994 total time=   0.0s\n",
      "[CV 5/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 5/5; 3/4] END ..............n_estimators=25;, score=0.978 total time=   0.0s\n",
      "[CV 1/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 1/5; 4/4] END ..............n_estimators=50;, score=0.969 total time=   0.0s\n",
      "[CV 2/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 2/5; 4/4] END ..............n_estimators=50;, score=0.979 total time=   0.0s\n",
      "[CV 3/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 3/5; 4/4] END ..............n_estimators=50;, score=0.976 total time=   0.0s\n",
      "[CV 4/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 4/5; 4/4] END ..............n_estimators=50;, score=0.995 total time=   0.0s\n",
      "[CV 5/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 5/5; 4/4] END ..............n_estimators=50;, score=0.980 total time=   0.0s\n",
      "Done training\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_of_param, list_of_model, list_of_tuned_model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNeighborsClassifier': {'model': RandomizedSearchCV(cv=5, estimator=KNeighborsClassifier(), n_iter=5, n_jobs=1,\n",
       "                     param_distributions={'n_neighbors': [50, 100, 200]},\n",
       "                     random_state=123, scoring='roc_auc', verbose=10),\n",
       "  'train_auc': 0.9822038567493112,\n",
       "  'valid_auc': 0.9722329620371388,\n",
       "  'best_params': {'n_neighbors': 200}},\n",
       " 'RandomForestClassifier': {'model': RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=5, n_jobs=1,\n",
       "                     param_distributions={'criterion': ['gini', 'entropy',\n",
       "                                                        'log_loss'],\n",
       "                                          'min_samples_split': [2, 4, 6, 8],\n",
       "                                          'n_estimators': [50, 80, 110, 140]},\n",
       "                     random_state=123, scoring='roc_auc', verbose=10),\n",
       "  'train_auc': 0.9998714416896235,\n",
       "  'valid_auc': 0.9760613531480057,\n",
       "  'best_params': {'n_estimators': 140,\n",
       "   'min_samples_split': 8,\n",
       "   'criterion': 'entropy'}},\n",
       " 'LogisticRegression': {'model': RandomizedSearchCV(cv=5, estimator=LogisticRegression(solver='sag'), n_iter=5,\n",
       "                     n_jobs=1,\n",
       "                     param_distributions={'C': [0.01, 0.1],\n",
       "                                          'max_iter': [100, 300, 500]},\n",
       "                     random_state=123, scoring='roc_auc', verbose=10),\n",
       "  'train_auc': 0.9864462809917355,\n",
       "  'valid_auc': 0.9765746895945501,\n",
       "  'best_params': {'max_iter': 100, 'C': 0.01}},\n",
       " 'XGBClassifier': {'model': RandomizedSearchCV(cv=5,\n",
       "                     estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                             callbacks=None,\n",
       "                                             colsample_bylevel=None,\n",
       "                                             colsample_bynode=None,\n",
       "                                             colsample_bytree=None,\n",
       "                                             early_stopping_rounds=None,\n",
       "                                             enable_categorical=False,\n",
       "                                             eval_metric=None, feature_types=None,\n",
       "                                             gamma=None, gpu_id=None,\n",
       "                                             grow_policy=None,\n",
       "                                             importance_type=None,\n",
       "                                             interaction_constraints=None,\n",
       "                                             learning_rate...\n",
       "                                             max_cat_threshold=None,\n",
       "                                             max_cat_to_onehot=None,\n",
       "                                             max_delta_step=None, max_depth=None,\n",
       "                                             max_leaves=None,\n",
       "                                             min_child_weight=None, missing=nan,\n",
       "                                             monotone_constraints=None,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             num_parallel_tree=None,\n",
       "                                             predictor=None, random_state=None, ...),\n",
       "                     n_iter=5, n_jobs=1,\n",
       "                     param_distributions={'n_estimators': [5, 10, 25, 50]},\n",
       "                     random_state=123, scoring='roc_auc', verbose=10),\n",
       "  'train_auc': 1.0,\n",
       "  'valid_auc': 0.9788072739259421,\n",
       "  'best_params': {'n_estimators': 25}}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_tuned_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           max_cat_threshold=None,\n",
       "                                           max_cat_to_onehot=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           max_leaves=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_iter=5, n_jobs=1,\n",
       "                   param_distributions={&#x27;n_estimators&#x27;: [5, 10, 25, 50]},\n",
       "                   random_state=123, scoring=&#x27;roc_auc&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           max_cat_threshold=None,\n",
       "                                           max_cat_to_onehot=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           max_leaves=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_iter=5, n_jobs=1,\n",
       "                   param_distributions={&#x27;n_estimators&#x27;: [5, 10, 25, 50]},\n",
       "                   random_state=123, scoring=&#x27;roc_auc&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           max_cat_threshold=None,\n",
       "                                           max_cat_to_onehot=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           max_leaves=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_iter=5, n_jobs=1,\n",
       "                   param_distributions={'n_estimators': [5, 10, 25, 50]},\n",
       "                   random_state=123, scoring='roc_auc', verbose=10)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = utils.pickle_load(CONFIG_DATA['test_clean_path'][0])\n",
    "y_test = utils.pickle_load(CONFIG_DATA['test_clean_path'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Get score\n",
    "score = roc_auc_score(y_test, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9823627696013689"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
